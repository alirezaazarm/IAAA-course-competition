{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Assignment Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rotate_image(image, angle, interpolation=cv2.INTER_LINEAR):\n",
    "    \"\"\"\n",
    "    Rotate an input image by a specified angle.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        angle: float\n",
    "            Angle in degrees by which to rotate the image.\n",
    "        interpolation: int, optional\n",
    "            Interpolation method to use. Default is cv2.INTER_LINEAR.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Rotated image.\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "\n",
    "    # Perform rotation\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height), flags=interpolation)\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "\n",
    "# Test rotation by 45 degrees with bilinear interpolation\n",
    "rotated_image_bilinear = rotate_image(image, 45, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Test rotation by 90 degrees with nearest neighbor interpolation\n",
    "rotated_image_nearest = rotate_image(image, 90, interpolation=cv2.INTER_NEAREST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, x, y, width, height):\n",
    "    \"\"\"\n",
    "    Crop an input image to a specified region of interest (ROI).\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        x: int\n",
    "            X-coordinate of the top-left corner of the ROI.\n",
    "        y: int\n",
    "            Y-coordinate of the top-left corner of the ROI.\n",
    "        width: int\n",
    "            Width of the ROI.\n",
    "        height: int\n",
    "            Height of the ROI.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Cropped image.\n",
    "    \"\"\"\n",
    "    cropped_image = image[y:y+height, x:x+width]\n",
    "    return cropped_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "\n",
    "# Define ROI coordinates and dimensions\n",
    "x, y, width, height = 100, 100, 300, 200\n",
    "\n",
    "# Crop image to the specified ROI\n",
    "cropped_image = crop_image(image, x, y, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_image(image, tx, ty):\n",
    "    \"\"\"\n",
    "    Translate (shift) an input image by the specified translation factors.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        tx: int\n",
    "            Translation factor along the x-axis.\n",
    "        ty: int\n",
    "            Translation factor along the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Translated image.\n",
    "    \"\"\"\n",
    "    rows, cols = image.shape[:2]\n",
    "    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n",
    "    return translated_image\n",
    "\n",
    "def scale_image(image, scale_x, scale_y):\n",
    "    \"\"\"\n",
    "    Scale an input image by the specified scale factors.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        scale_x: float\n",
    "            Scale factor along the x-axis.\n",
    "        scale_y: float\n",
    "            Scale factor along the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Scaled image.\n",
    "    \"\"\"\n",
    "    scaled_image = cv2.resize(image, None, fx=scale_x, fy=scale_y)\n",
    "    return scaled_image\n",
    "\n",
    "def shear_image(image, shear_x, shear_y):\n",
    "    \"\"\"\n",
    "    Shear an input image by the specified shear factors.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        shear_x: float\n",
    "            Shear factor along the x-axis.\n",
    "        shear_y: float\n",
    "            Shear factor along the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Sheared image.\n",
    "    \"\"\"\n",
    "    rows, cols = image.shape[:2]\n",
    "    shear_matrix = np.float32([[1, shear_x, 0], [shear_y, 1, 0]])\n",
    "    sheared_image = cv2.warpAffine(image, shear_matrix, (cols, rows))\n",
    "    return sheared_image\n",
    "\n",
    "def reflect_image(image, axis):\n",
    "    \"\"\"\n",
    "    Reflect (flip) an input image along the specified axis.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        axis: int\n",
    "            Axis along which to reflect the image. 0 for vertical, 1 for horizontal.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Reflected image.\n",
    "    \"\"\"\n",
    "    reflected_image = cv2.flip(image, axis)\n",
    "    return reflected_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "\n",
    "# Test individual transformations\n",
    "translated_image = translate_image(image, 50, 50)\n",
    "scaled_image = scale_image(image, 0.5, 0.5)\n",
    "sheared_image = shear_image(image, 0.2, 0.2)\n",
    "reflected_vertical_image = reflect_image(image, 0)\n",
    "reflected_horizontal_image = reflect_image(image, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, src_points, dst_points):\n",
    "    \"\"\"\n",
    "    Perform perspective transformation on an input image to correct distortions caused by the viewpoint of the camera.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        src_points: list of tuples\n",
    "            List of four source points defining the region of interest (ROI) in the input image.\n",
    "        dst_points: list of tuples\n",
    "            List of four destination points defining the desired perspective-transformed region.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Perspective-transformed image.\n",
    "    \"\"\"\n",
    "    # Convert points to numpy arrays\n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "\n",
    "    # Calculate perspective transform matrix\n",
    "    perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    # Apply perspective transform\n",
    "    transformed_image = cv2.warpPerspective(image, perspective_matrix, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return transformed_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "\n",
    "# Define source points (ROI) and destination points for perspective transformation\n",
    "src_points = [(150, 150), (450, 150), (450, 350), (150, 350)]\n",
    "dst_points = [(200, 100), (400, 100), (400, 300), (200, 300)]\n",
    "\n",
    "# Perform perspective transformation\n",
    "transformed_image = perspective_transform(image, src_points, dst_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def index_colors(image, k):\n",
    "    \"\"\"\n",
    "    Index colors in an image using k-means clustering.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image.\n",
    "        k: int\n",
    "            Number of clusters (colors) to group similar colors into.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Image with indexed colors.\n",
    "    \"\"\"\n",
    "    # Reshape image to a 2D array of pixels (rows) by color channels (columns)\n",
    "    pixels = image.reshape(-1, 3)\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Get cluster centroids (colors)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Get labels for each pixel indicating the nearest centroid\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Replace each pixel with its nearest centroid color\n",
    "    indexed_image = centroids[labels].reshape(image.shape)\n",
    "\n",
    "    return indexed_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "\n",
    "# Apply color indexing with k-means clustering\n",
    "k = 8  # Number of clusters\n",
    "indexed_image = index_colors(image, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Space Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def convert_rgb_to_hsv(image):\n",
    "    \"\"\"\n",
    "    Convert an image from RGB color space to HSV color space.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image in RGB color space.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Image in HSV color space.\n",
    "    \"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_image\n",
    "\n",
    "def convert_rgb_to_lab(image):\n",
    "    \"\"\"\n",
    "    Convert an image from RGB color space to LAB color space.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image in RGB color space.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Image in LAB color space.\n",
    "    \"\"\"\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    return lab_image\n",
    "\n",
    "def convert_rgb_to_ycbcr(image):\n",
    "    \"\"\"\n",
    "    Convert an image from RGB color space to YCbCr color space.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy.ndarray\n",
    "            Input image in RGB color space.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray\n",
    "            Image in YCbCr color space.\n",
    "    \"\"\"\n",
    "    ycbcr_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    return ycbcr_image\n",
    "\n",
    "# Load sample image\n",
    "image = cv2.imread('logo.png')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert image to HSV color space\n",
    "image_hsv = convert_rgb_to_hsv(image_rgb)\n",
    "\n",
    "# Convert image to LAB color space\n",
    "image_lab = convert_rgb_to_lab(image_rgb)\n",
    "\n",
    "# Convert image to YCbCr color space\n",
    "image_ycbcr = convert_rgb_to_ycbcr(image_rgb)\n",
    "\n",
    "# Display original image and its converted versions in each color space\n",
    "cv2.imshow('Original Image', image_rgb)\n",
    "cv2.imshow('HSV Color Space', image_hsv)\n",
    "cv2.imshow('LAB Color Space', image_lab)\n",
    "cv2.imshow('YCbCr Color Space', image_ycbcr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
